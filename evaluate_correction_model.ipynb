{"cells":[{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOTP5f5yg6D2","executionInfo":{"status":"ok","timestamp":1647956625334,"user_tz":240,"elapsed":303,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}},"outputId":"92ab420c-4021-49a3-aef1-9808b4daf854"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Mar 22 13:43:45 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    34W / 250W |  10145MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"x1Wpy3SHVT7T","executionInfo":{"status":"ok","timestamp":1647950942894,"user_tz":240,"elapsed":234191,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}}},"outputs":[],"source":["%%capture\n","# clone repro and install deps\n","!git clone -b main https://github.com/dleve123/topics-in-nlp-repro-project\n","%cd /content/topics-in-nlp-repro-project/\n","!pip install -r requirements.txt\n","\n","# mount validation data\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1647956618471,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"},"user_tz":240},"id":"uQE75uJhXolK","outputId":"35c8d4d5-bc25-4962-9bce-57b3411f462c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/topics-in-nlp-repro-project\n"]}],"source":["%cd /content/topics-in-nlp-repro-project/"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":457,"status":"ok","timestamp":1647950943348,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"},"user_tz":240},"id":"_e8qf_-zWyL9","outputId":"dcb8831b-0351-442a-e251-5ad8d811d340"},"outputs":[{"output_type":"stream","name":"stdout","text":["HEAD is now at 528cc61 Changed default bath size to 2\n"]}],"source":["! git fetch\n","! git reset --hard origin/main"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ZXv_G8zVnbq"},"outputs":[],"source":["# TODO fix later, for now run in cell\n","# ! python inference_correction_model.py /content/drive/MyDrive/CS6741/replication/data/tokenized/val.tokenized.jsonl"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"3kW5UZziXEHS","executionInfo":{"status":"ok","timestamp":1647950951746,"user_tz":240,"elapsed":8400,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}}},"outputs":[],"source":["import argparse\n","from time import perf_counter\n","from model.correction_model import CorrectionModel\n","from preprocessing.prepare_train_dataset import tensors_from_jsonl_filepath\n","\n","\n","test_data = tensors_from_jsonl_filepath(\"/content/drive/MyDrive/CS6741/replication/data/tokenized/test.bart.tokenized.jsonl\")"]},{"cell_type":"code","source":["import random\n","random.seed(42)\n","test_subset = random.choices(test_data, k=250)"],"metadata":{"id":"7HZYxPHPqK65","executionInfo":{"status":"ok","timestamp":1647956696239,"user_tz":240,"elapsed":202,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WHXMfpD9dI_l"},"source":["## Utils"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"UIaHllFUcUn8","executionInfo":{"status":"ok","timestamp":1647950951748,"user_tz":240,"elapsed":17,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}}},"outputs":[],"source":["from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import torch\n","\n","def eval_get_corrected_indices(prediction_logits):\n","  FAITHFUL_CLASS = 1\n","\n","  corrected_indices = []\n","  for idx, logits in enumerate(prediction_logits):\n","    # Get the top logit of the faithful class\n","    max_ranked = logits[:, FAITHFUL_CLASS].argmax().item()\n","    if max_ranked != 0:\n","      corrected_indices.append((idx, max_ranked))\n","\n","  ratio = len(corrected_indices)/len(prediction_logits)\n","  print(f\"Corrected: {len(corrected_indices)} ({ratio:.2%})\")\n","  return corrected_indices\n","\n","def decode_summary(model, tensor):\n","    end_idx = (tensor == model.tokenizer.eos_token_id).nonzero()[0].item()\n","    return model.tokenizer.decode(\n","        tensor[:end_idx],\n","        skip_special_tokens=True\n","    ), model.tokenizer.decode(\n","        tensor[end_idx:],\n","        skip_special_tokens=True\n","    )\n","  \n","def decode_corrected_summaries(dset, model, corrected_indices):\n","  summaries = []\n","  for data_idx, sum_idx in tqdm(corrected_indices):\n","    corr_summary, source = decode_summary(\n","        model, \n","        dset[data_idx][sum_idx]\n","    )\n","    orig_summary, source = decode_summary(\n","        model, \n","        dset[data_idx][0]\n","    )\n","    summaries.append({\n","        \"corrected\": corr_summary,\n","        \"original\": orig_summary,\n","        \"source\": source\n","    })\n","  return summaries"]},{"cell_type":"markdown","metadata":{"id":"7DT5Fm4zcE4Q"},"source":["## EVAL - Run FEQA"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"xcxWxPTPNK6f","executionInfo":{"status":"ok","timestamp":1647956702552,"user_tz":240,"elapsed":215,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}}},"outputs":[],"source":["feqa_score_cache = {}"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":552,"status":"ok","timestamp":1647956703441,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"},"user_tz":240},"id":"ii4xdPoSgIxm","outputId":"565b11b0-990a-49ab-a935-b4eb2392f02c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package benepar_en3 to /root/nltk_data...\n","[nltk_data]   Package benepar_en3 is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["# Resolve paths from root project directory\n","import os\n","import sys\n","from eval_feqa import download_models, evaluate as evaluate_feqa\n","\n","download_models()\n","\n","def evaluate_feqa_with_cache(docs, sums):\n","  cache_miss_docs = []\n","  cache_miss_sums = []\n","  cache_miss_idx = []\n","  scores = []\n","  for j, (sum, doc) in enumerate(zip(sums, docs)):\n","    if sum in feqa_score_cache:\n","      scores.append(feqa_score_cache[sum])\n","    else:\n","      scores.append(None)\n","      cache_miss_docs.append(doc)\n","      cache_miss_sums.append(sum)\n","      cache_miss_idx.append(j)\n","  if len(cache_miss_docs) > 0:\n","    eval = evaluate_feqa(\n","        cache_miss_docs,\n","        cache_miss_sums,\n","        \"/content/drive/MyDrive/CS6741/replication/feqa-assets/squad1.0\",\n","        \"/content/drive/MyDrive/CS6741/replication/feqa-assets/checkpoints\"\n","    )\n","    for score, idx, sum in zip(eval, cache_miss_idx, cache_miss_sums):\n","      scores[idx] = score\n","      feqa_score_cache[sum] = score\n","  return scores\n","\n","def run_feqa(summaries, N=100):\n","  summaries = summaries[:N]\n","  original_sums = [x[\"original\"] for x in summaries]\n","  corrected_sums = [x[\"corrected\"] for x in summaries]\n","  source_docs = [x[\"source\"] for x in summaries]\n","      \n","  orig_feqa_scores = evaluate_feqa_with_cache(\n","      source_docs,\n","      original_sums\n","  )\n","  corr_feqa_scores = evaluate_feqa_with_cache(\n","      source_docs,\n","      corrected_sums,\n","  )\n","\n","  return orig_feqa_scores, corr_feqa_scores"]},{"cell_type":"markdown","metadata":{"id":"Rd07LHjJjpfp"},"source":["## Caching feqa scores"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"8YR1W1Fhiyer","executionInfo":{"status":"ok","timestamp":1647971433055,"user_tz":240,"elapsed":189,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9eef010b-3882-4b03-b8b0-363dcbf46f84"},"outputs":[{"output_type":"stream","name":"stdout","text":["Local Cache 4798\n","Persisted Cache 4798\n"]}],"source":["import pickle\n","with open(\"/content/drive/MyDrive/CS6741/replication/feqa-assets/feqa_score_cache.pickle\", \"rb\") as f:\n","  persisted_feqa_score_cache = pickle.load(f)\n","\n","print(\"Local Cache\", len(feqa_score_cache))\n","print(\"Persisted Cache\", len(persisted_feqa_score_cache))\n","\n","def cache_update(source, target):\n","  updates = 0\n","  for key,value in source.items():\n","    if key not in target:\n","      target[key] = value\n","      updates += 1\n","  return updates\n","\n","local_updates = cache_update(\n","    source=persisted_feqa_score_cache,\n","    target=feqa_score_cache\n",")\n","persisted_updates = cache_update(\n","    source=feqa_score_cache,\n","    target=persisted_feqa_score_cache\n",")\n","\n","if local_updates > 0:\n","  print(f\"Added {local_updates} sums to local cache\")\n","\n","if persisted_updates > 0:\n","  print(f\"Added {persisted_updates} sums to persisted cache, writing...\")\n","\n","  with open(\"/content/drive/MyDrive/CS6741/replication/feqa-assets/feqa_score_cache.pickle\", \"wb\") as f:\n","    pickle.dump(persisted_feqa_score_cache, f)"]},{"cell_type":"markdown","metadata":{"id":"BfqcSNb1LwG5"},"source":["### Random baseline"]},{"cell_type":"code","source":["baseline_model = CorrectionModel()\n","baseline_predictions = baseline_model.batch_inference(test_subset)\n","baseline_corrected_indices = eval_get_corrected_indices(baseline_predictions)\n","baseline_summaries = decode_corrected_summaries(\n","    test_subset,\n","    baseline_model,\n","    baseline_corrected_indices\n",")\n","baseline_summaries[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qd3XoqM3782x","outputId":"c50cd514-295a-45c8-b7d0-fc81a6343d35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.out_proj.bias', 'classification_head.out_proj.weight', 'classification_head.dense.bias', 'classification_head.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"," 97%|█████████▋| 242/250 [00:39<00:00,  8.73it/s]"]}]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":925377,"status":"ok","timestamp":1647956184149,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"},"user_tz":240},"id":"2ojuoKxPgaWt","outputId":"9dde9129-4239-4f7c-c411-277979a6896f"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Generating questions...\n","Tokenizing summaries for q-gen...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:46: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n","  'with `validate_args=False` to turn off validation.')\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Generating questions (batch 0/1648)...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beams_buf = indices_buf // vocab_size\n","/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  unfin_idx = idx // beam_size\n"]},{"output_type":"stream","name":"stdout","text":["Generating questions (batch 64/1648)...\n","Generating questions (batch 128/1648)...\n","Generating questions (batch 192/1648)...\n","Generating questions (batch 256/1648)...\n","Generating questions (batch 320/1648)...\n","Generating questions (batch 384/1648)...\n","Generating questions (batch 448/1648)...\n","Generating questions (batch 512/1648)...\n","Generating questions (batch 576/1648)...\n","Generating questions (batch 640/1648)...\n","Generating questions (batch 704/1648)...\n","Generating questions (batch 768/1648)...\n","Generating questions (batch 832/1648)...\n","Generating questions (batch 896/1648)...\n","Generating questions (batch 960/1648)...\n","Generating questions (batch 1024/1648)...\n","Generating questions (batch 1088/1648)...\n","Generating questions (batch 1152/1648)...\n","Generating questions (batch 1216/1648)...\n","Generating questions (batch 1280/1648)...\n","Generating questions (batch 1344/1648)...\n","Generating questions (batch 1408/1648)...\n","Generating questions (batch 1472/1648)...\n","Generating questions (batch 1536/1648)...\n","Generating questions (batch 1600/1648)...\n","Getting answers...\n","Computing metrics...\n","Generating questions...\n","Tokenizing summaries for q-gen...\n","Generating questions (batch 0/1664)...\n","Generating questions (batch 64/1664)...\n","Generating questions (batch 128/1664)...\n","Generating questions (batch 192/1664)...\n","Generating questions (batch 256/1664)...\n","Generating questions (batch 320/1664)...\n","Generating questions (batch 384/1664)...\n","Generating questions (batch 448/1664)...\n","Generating questions (batch 512/1664)...\n","Generating questions (batch 576/1664)...\n","Generating questions (batch 640/1664)...\n","Generating questions (batch 704/1664)...\n","Generating questions (batch 768/1664)...\n","Generating questions (batch 832/1664)...\n","Generating questions (batch 896/1664)...\n","Generating questions (batch 960/1664)...\n","Generating questions (batch 1024/1664)...\n","Generating questions (batch 1088/1664)...\n","Generating questions (batch 1152/1664)...\n","Generating questions (batch 1216/1664)...\n","Generating questions (batch 1280/1664)...\n","Generating questions (batch 1344/1664)...\n","Generating questions (batch 1408/1664)...\n","Generating questions (batch 1472/1664)...\n","Generating questions (batch 1536/1664)...\n","Generating questions (batch 1600/1664)...\n","Getting answers...\n","Computing metrics...\n","Original sums FEQA scores 0.2610481635090159\n","Corrected sums FEQA scores 0.23024442257915975\n","DIFF -0.030803740929856133\n"]}],"source":["import numpy as np\n","orig_feqa_scores, corr_feqa_scores = run_feqa(baseline_summaries, len(test_subset))\n","print(\"Original sums FEQA scores\", np.mean(orig_feqa_scores))\n","print(\"Corrected sums FEQA scores\", np.mean(corr_feqa_scores))\n","\n","print(\"DIFF\", np.mean(corr_feqa_scores) - np.mean(orig_feqa_scores))"]},{"cell_type":"markdown","metadata":{"id":"QBNf04v7LJmj"},"source":["# Train v1"]},{"cell_type":"markdown","metadata":{"id":"UnpE3UXdL1B3"},"source":["### Checkpoint 15k steps"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"fQ8_sxZaOqZ3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647956773727,"user_tz":240,"elapsed":46803,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}},"outputId":"3a121391-e749-4d3d-fc9a-145e8249c031"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 250/250 [00:40<00:00,  6.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Corrected: 73 (29.20%)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 73/73 [00:02<00:00, 30.04it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'corrected': 'A restaurant owner in southern Spain has described a \"stampede\" in which a group of ¬2,000 diners left his restaurant in the middle of a meal.',\n"," 'original': 'A restaurant owner in southern Spain has described a \"stampede\" in which a group of 20 diners left his restaurant in the middle of a meal.',\n"," 'source': 'The Romanian diners, who had paid a deposit of â‚¬900 ($950; Â£770), left the El Carmen restaurant in Bembibre as dessert was due to be served, Antonio Rodriguez said.\\n\"It happened in the space of a minute,\" he said. \"It was something they had planned and they left in a stampede.\"\\nThe diners owe â‚¬2,000 more, he said.\\nMr Rodriguez gave police the details on the reservation but said he held out little hope of being repaid. Police told El Pais newspaper they had not yet been able to contact any of the diners.\\nThe diners had consumed starters, a main course and 30 bottles of various alcoholic drinks, he said, adding that it was the first time in 35 years of working in the restaurant trade that he had seen seen anything comparable.'}"]},"metadata":{},"execution_count":48}],"source":["checkpoint_model = CorrectionModel(\n","  model_checkpoint=\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/epoch-0_totalsteps-15000\"\n",")\n","checkpoint_predictions = checkpoint_model.batch_inference(test_subset)\n","checkpoint_corrected_indices = eval_get_corrected_indices(checkpoint_predictions)\n","checkpoint_summaries = decode_corrected_summaries(\n","    test_subset,\n","    checkpoint_model,\n","    checkpoint_corrected_indices\n",")\n","checkpoint_summaries[0]"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"3TkBkSycNDhw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647956773728,"user_tz":240,"elapsed":16,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}},"outputId":"f1aa183d-1b1d-4bfb-af99-11260ca87ab4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Original sums FEQA scores 0.2892756464769482\n","Corrected sums FEQA scores 0.24504024798606372\n","DIFF -0.04423539849088448\n"]}],"source":["import numpy as np\n","orig_feqa_scores, corr_feqa_scores = run_feqa(\n","  checkpoint_summaries, N=len(test_subset)\n",")\n","print(\"Original sums FEQA scores\", np.mean(orig_feqa_scores))\n","print(\"Corrected sums FEQA scores\", np.mean(corr_feqa_scores))\n","\n","print(\"DIFF\", np.mean(corr_feqa_scores) - np.mean(orig_feqa_scores))"]},{"cell_type":"markdown","metadata":{"id":"HW0TbyHLVqRL"},"source":["## Checkpoint 40k steps"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":178687,"status":"ok","timestamp":1647897592444,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7ptkoeHzG-SgTUcatA-2LM4vPqWpUfFdo2DtG=s64","userId":"01882518168555759889"},"user_tz":240},"id":"i-hANwp9Vrxp","outputId":"eb7b20db-37aa-46a8-85c3-6f7992490b9f"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 895/895 [02:19<00:00,  6.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Corrected: 872 (97.43%)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 872/872 [00:30<00:00, 28.95it/s]\n"]},{"data":{"text/plain":["{'corrected': 'A judge in the US has denied bail to one people accused of beating a black man and forcing him to kiss the floor in a Facebook Live video.',\n"," 'original': 'A judge in the US has denied bail to four people accused of beating a black man and forcing him to kiss the floor in a Facebook Live video.',\n"," 'source': 'Jordan Hill, Brittany Covington and Tesfaye Cooper, all 18, and Tanishia Covington, 24, appeared in a Chicago court on Friday.\\nThe four have been charged with hate crimes and aggravated kidnapping and battery, among other things.\\nAn online fundraiser for their victim has collected $51,000 (Â£42,500) so far.\\nDenying the four suspects bail, Judge Maria Kuriakos Ciesil asked: \"Where was your sense of decency?\"\\nProsecutors told the court the beating started in a van and continued at a house, where the suspects allegedly forced the 18-year-old white victim, who suffers from schizophrenia and attention deficit disorder, to drink toilet water and kiss the floor.\\nPolice allege the van was earlier stolen by Mr Hill, who is also accused of demanding $300 from the victim\\'s mother while they held him captive, according to the Chicago Tribune.\\nThe court was also told the suspects stuffed a sock into his mouth, taped his mouth shut and bound his hands with a belt.\\nIn a video made for Facebook Live which was watched millions of times, the assailants can be heard making derogatory statements against white people and Donald Trump.\\nThe victim had been dropped off at a McDonalds to meet Mr Hill - who was one of his friends - on 31 December.\\nHe was found by a police officer on Tuesday, 3 January, a day after he was reported missing by his parents.\\nProsecutors say the suspects each face two hate crimes counts, one because of the victim\\'s race and the other because of his disabilities.'}"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["checkpoint_model = CorrectionModel(\n","  model_checkpoint=\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/epoch-0_totalsteps-40000\"\n",")\n","checkpoint_predictions = checkpoint_model.batch_inference(test_subset)\n","checkpoint_corrected_indices = eval_get_corrected_indices(checkpoint_predictions)\n","checkpoint_summaries = decode_corrected_summaries(\n","    checkpoint_model,\n","    checkpoint_corrected_indices\n",")\n","checkpoint_summaries[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":567345,"status":"ok","timestamp":1647898483480,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7ptkoeHzG-SgTUcatA-2LM4vPqWpUfFdo2DtG=s64","userId":"01882518168555759889"},"user_tz":240},"id":"rxvpLDysVx-X","outputId":"4250ff55-fb22-450d-f499-a3fb1dbc56ae"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package benepar_en3 to /root/nltk_data...\n","[nltk_data]   Package benepar_en3 is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["Generating questions...\n","Tokenizing summaries for q-gen...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:46: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n","  'with `validate_args=False` to turn off validation.')\n"]},{"name":"stdout","output_type":"stream","text":["Generating questions (batch 0/872)...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beams_buf = indices_buf // vocab_size\n","/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  unfin_idx = idx // beam_size\n"]},{"name":"stdout","output_type":"stream","text":["Generating questions (batch 64/872)...\n","Generating questions (batch 128/872)...\n","Generating questions (batch 192/872)...\n","Generating questions (batch 256/872)...\n","Generating questions (batch 320/872)...\n","Generating questions (batch 384/872)...\n","Generating questions (batch 448/872)...\n","Generating questions (batch 512/872)...\n","Generating questions (batch 576/872)...\n","Generating questions (batch 640/872)...\n","Generating questions (batch 704/872)...\n","Generating questions (batch 768/872)...\n","Generating questions (batch 832/872)...\n","Getting answers...\n","Computing metrics...\n","Generating questions...\n","Tokenizing summaries for q-gen...\n","Generating questions (batch 0/835)...\n","Generating questions (batch 64/835)...\n","Generating questions (batch 128/835)...\n","Generating questions (batch 192/835)...\n","Generating questions (batch 256/835)...\n","Generating questions (batch 320/835)...\n","Generating questions (batch 384/835)...\n","Generating questions (batch 448/835)...\n","Generating questions (batch 512/835)...\n","Generating questions (batch 576/835)...\n","Generating questions (batch 640/835)...\n","Generating questions (batch 704/835)...\n","Generating questions (batch 768/835)...\n","Generating questions (batch 832/835)...\n","Getting answers...\n","Computing metrics...\n","Original sums FEQA scores 0.26251053749149517\n","Corrected sums FEQA scores 0.22568118927958772\n","DIFF -0.03682934821190745\n"]}],"source":["import numpy as np\n","orig_feqa_scores, corr_feqa_scores = run_feqa(\n","  checkpoint_summaries, N=100\n",")\n","print(\"Original sums FEQA scores\", np.mean(orig_feqa_scores))\n","print(\"Corrected sums FEQA scores\", np.mean(corr_feqa_scores))\n","\n","print(\"DIFF\", np.mean(corr_feqa_scores) - np.mean(orig_feqa_scores))"]},{"cell_type":"markdown","metadata":{"id":"TRQ0iZkmoIdK"},"source":["## Checkpoint 60k steps"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240,"referenced_widgets":["e22c3246123346269f417d09e7650cd3","8e5c8e2a417341e386c700f02ccbd7f1","e71f97392ee04799810bea4272c645b2","a13cd5d961e842a19934a854e6dfe68a","5be7398aac6142c5984835498d8213ec","20d32e3d136f48d99c034c7f6a80d7c7","e991f4c466b24e8687fe5a41b69d358b","310011821b5d498c9032b6ad83970882","9ee8b0d16b6b4d70a93621cfee62f13a","f4dc0e7ba1bf4febb69cccb158167c6a","6f1602e7d99d4d358012b1420f93adc3","6485d3619d894e58a7f6c02f555b85a9","5de77521beb6448299b55e4d3cd3fa48","8e40738381af4d768e2481776ca8bd5f","c1c4fafa51424c9f8ce6735b5cb4f300","7bbcbd4ad7d24dd5929ffb5af1ee2ec0","3f3a292e9cf64885aa5c60f866c43c75","0ae9750ff7864e978325b095095c9248","603a0a3866d7484e852249cf65441ec1","5abef602316d462a9e655c7e4d8719d9","9f0b9fa631b342f58268e5a8f91bb660","c049e69f60a042a0972ea68003aad62d","65d4d18e3d614c28bb10d4e893f1deee","92a7ebd8c7f245b0b736dd74e70fc92e","e88f532c4fd44bd8a7df4b5aee975c46","f567774d13744a848ff9ea9e898ed3e6","957f949b11bb427f8aa0302a38804277","25248edb44d64bb4b2a62fd3bf18191b","e446227cb57a4ae487604a3f17a122a6","c26eecf80f1641b786c1d0ec6568cacd","52335bfac6a641d18d11695c5a4824d2","5dbab2a687a44b0d98cf528ad27d0e10","04d44b9a008f41fa80cc6bd28ab8612b"]},"executionInfo":{"elapsed":204983,"status":"ok","timestamp":1647911602642,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7ptkoeHzG-SgTUcatA-2LM4vPqWpUfFdo2DtG=s64","userId":"01882518168555759889"},"user_tz":240},"id":"cG8EGtULoLry","outputId":"582f7216-b390-455c-ff3c-92d70597821e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e22c3246123346269f417d09e7650cd3","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6485d3619d894e58a7f6c02f555b85a9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65d4d18e3d614c28bb10d4e893f1deee","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.68k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [02:33<00:00,  6.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Corrected: 987 (98.70%)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 987/987 [00:35<00:00, 27.63it/s]\n"]},{"data":{"text/plain":["{'corrected': 'World number one Magnus Norman was beaten in five sets by Stan Wawrinka in the French Open final.',\n"," 'original': 'World number one Novak Djokovic was beaten in five sets by Stan Wawrinka in the French Open final.',\n"," 'source': 'The Swiss eighth seed played magnificently in a 4-6 6-4 6-3 6-4 victory at Roland Garros.\\nWawrinka, 30, brought an end to Djokovic\\'s 28-match winning streak as he claimed his second Grand Slam title.\\nMedia playback is not supported on this device\\nDjokovic had been hoping to become the eighth man to complete the set of all four major titles.\\nBut the Serb will have to wait at least another 12 months before attempting to match the full set of major titles collected by Andre Agassi, Don Budge, Roy Emerson, Roger Federer, Rod Laver, Rafael Nadal and Fred Perry.\\nThe 28-year-old had been a strong favourite to finally get his hands on the Coupe des Mousquetaires after beating nine-time champion Rafael Nadal and third seed Andy Murray, but he was outplayed by Wawrinka.\\n\"It was an incredible atmosphere on court and I felt emotion like I never have before,\" said Wawrinka.\\n\"I would like to thank my coach Magnus Norman. You played in the final without winning but this victory is yours as well as mine.\"\\nDjokovic was effusive in his praise for the new champion: \"There are things that are more important in life than victories and that is character and respect - Stan you are a great champion with big heart.\"\\nTheir last four matches in Grand Slams had gone to five sets and this was every bit as good in terms of quality, with Wawrinka hitting 60 winners as his aggression broke down the seemingly invincible Djokovic defence.\\nThe victory makes him only the second Swiss to win at Roland Garros after Roger Federer, the man he beat in the quarter-finals.\\nHaving lost the first set of the final following a poor service game at 3-3, Wawrinka came storming back with a barrage of winners that left Djokovic looking lost for a response.\\nFour break points came and went in the second set before the fifth arrived in the shape of a set point, and Wawrinka finally converted to level the match.\\nIt was merely a sign of things to come as the eighth seed tore into the Djokovic serve in the third, and despite seeing off three break points for 1-1, there was little the top seed could do four games later.\\nA brilliant forehand winner was followed by an equally breathtaking backhand to earn three break points, and the first was converted as Wawrinka moved forward and hammered a short ball.\\nThe crowd on Court Philippe Chatrier roared as the Swiss hit an outrageous winner around the net post on his way to securing the set.\\nDjokovic was now facing a third French Open final defeat and he dug in, taking advantage of a lull at the opposite end of the court to fashion a 3-0 lead in the fourth.\\nThe match was now on Wawrinka\\'s racquet, however, and he came storming back to level at 3-3 after some brilliant defence earned him the break.\\nDjokovic called on everything he had to stay in touch, finding two volleys - the second a lunging effort reminiscent of his coach Boris Becker - to save break points with the score level in the set.\\nMoments later it looked as though Djokovic would force the fifth set that had seemed inevitable as he moved 0-40 up, but there was another burst of brilliance to come from Wawrinka.\\nA volley, a backhand and a serve got him out of trouble, and he rode the wave of five successive points into the next game as two screaming backhand passes at 4-4 gave him the chance to serve out for the title.\\nIt was never likely to be easy and, after a possible ace was overruled by the umpire on his first match point, the Swiss had to face a break point as Djokovic clung on to his career Slam hopes.\\nThe Serb could only send a forehand wide under pressure, and given a second opportunity to take the championship, Wawrinka steered another of those trademark backhands down the line and raised his arms in triumph.'}"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["checkpoint_model = CorrectionModel(\n","  model_checkpoint=\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/epoch-0_totalsteps-60000\"\n",")\n","checkpoint_predictions = checkpoint_model.batch_inference(test_subset)\n","checkpoint_corrected_indices = eval_get_corrected_indices(checkpoint_predictions)\n","checkpoint_summaries = decode_corrected_summaries(\n","    checkpoint_model,\n","    checkpoint_corrected_indices\n",")\n","checkpoint_summaries[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":617675,"status":"ok","timestamp":1647912220304,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7ptkoeHzG-SgTUcatA-2LM4vPqWpUfFdo2DtG=s64","userId":"01882518168555759889"},"user_tz":240},"id":"77K1lesRoOJQ","outputId":"94f7ca0b-0222-45f6-ab9c-bacc72b4b326"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package benepar_en3 to /root/nltk_data...\n","[nltk_data]   Unzipping models/benepar_en3.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","1042301B [00:00, 7343195.28B/s]\n","456318B [00:00, 9604064.61B/s]\n"]},{"name":"stdout","output_type":"stream","text":["Generating questions...\n","Tokenizing summaries for q-gen...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:46: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n","  'with `validate_args=False` to turn off validation.')\n"]},{"name":"stdout","output_type":"stream","text":["Generating questions (batch 0/855)...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beams_buf = indices_buf // vocab_size\n","/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  unfin_idx = idx // beam_size\n"]},{"name":"stdout","output_type":"stream","text":["Generating questions (batch 64/855)...\n","Generating questions (batch 128/855)...\n","Generating questions (batch 192/855)...\n","Generating questions (batch 256/855)...\n","Generating questions (batch 320/855)...\n","Generating questions (batch 384/855)...\n","Generating questions (batch 448/855)...\n","Generating questions (batch 512/855)...\n","Generating questions (batch 576/855)...\n","Generating questions (batch 640/855)...\n","Generating questions (batch 704/855)...\n","Generating questions (batch 768/855)...\n","Generating questions (batch 832/855)...\n","Getting answers...\n","Computing metrics...\n","Generating questions...\n","Tokenizing summaries for q-gen...\n","Generating questions (batch 0/830)...\n","Generating questions (batch 64/830)...\n","Generating questions (batch 128/830)...\n","Generating questions (batch 192/830)...\n","Generating questions (batch 256/830)...\n","Generating questions (batch 320/830)...\n","Generating questions (batch 384/830)...\n","Generating questions (batch 448/830)...\n","Generating questions (batch 512/830)...\n","Generating questions (batch 576/830)...\n","Generating questions (batch 640/830)...\n","Generating questions (batch 704/830)...\n","Generating questions (batch 768/830)...\n","Getting answers...\n","Computing metrics...\n","Original sums FEQA scores 0.24907885225208198\n","Corrected sums FEQA scores 0.19529542883905887\n","DIFF -0.05378342341302311\n"]}],"source":["import numpy as np\n","orig_feqa_scores, corr_feqa_scores = run_feqa(\n","  checkpoint_summaries, N=100\n",")\n","print(\"Original sums FEQA scores\", np.mean(orig_feqa_scores))\n","print(\"Corrected sums FEQA scores\", np.mean(corr_feqa_scores))\n","\n","print(\"DIFF\", np.mean(corr_feqa_scores) - np.mean(orig_feqa_scores))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RAI3mvKzP__f"},"outputs":[],"source":["# Max examples per doc=3\n","checkpoint_model = CorrectionModel(\n","  model_checkpoint=\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/epoch-0_totalsteps-60000\"\n",")\n","checkpoint_predictions = checkpoint_model.batch_inference(test_subset, max_examples_per_doc=3)\n","checkpoint_corrected_indices = eval_get_corrected_indices(checkpoint_predictions)\n","checkpoint_summaries = decode_corrected_summaries(\n","    checkpoint_model,\n","    checkpoint_corrected_indices\n",")\n","checkpoint_summaries[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D6TT53PQQE4Y"},"outputs":[],"source":["import numpy as np\n","orig_feqa_scores, corr_feqa_scores = run_feqa(\n","  checkpoint_summaries, N=100\n",")\n","print(\"Original sums FEQA scores\", np.mean(orig_feqa_scores))\n","print(\"Corrected sums FEQA scores\", np.mean(corr_feqa_scores))\n","\n","print(\"DIFF\", np.mean(corr_feqa_scores) - np.mean(orig_feqa_scores))"]},{"cell_type":"markdown","metadata":{"id":"wruLoEhULM2e"},"source":["## Checkpoint 100k steps (epoch 1)"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47612,"status":"ok","timestamp":1647957199368,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"},"user_tz":240},"id":"B133wUP1Lepa","outputId":"6de903cc-93aa-4804-b9bd-97cf14bbcaa5"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 250/250 [00:39<00:00,  6.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Corrected: 64 (25.60%)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 64/64 [00:02<00:00, 27.99it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'corrected': 'When Josephine broke her nose on the London Underground, it was the beginning of the end for Oh Wonder, the songwriting duo who went on to become a global sensation.',\n"," 'original': 'When Josephine Skousen broke her nose on the London Underground, it was the beginning of the end for Oh Wonder, the songwriting duo who went on to become a global sensation.',\n"," 'source': 'It forced the band to remain anonymous for almost a year: No photographs, no interviews, no videos.\\nBut there was an upside. Last year, as she caught a train home from Heathrow, she sat next to a passenger \"covered in blood [with] no teeth, looking sorry for himself\".\\n\"I tentatively went up to him and his girlfriend and said, \\'I just wanted to let you know you\\'ll be fine\\',\" recalls the 27-year-old.\\n\"\\'Go to the dentist tomorrow, don\\'t panic, you\\'ll be great\\'. And he was like, \\'Oh, thank you so much!\\'.\\n\"And then this guy opposite us piped up, \\'I broke my nose, too!\\'. And suddenly this whole little carriage was talking about their injuries, which was remarkable.\\n\"When I got off the Tube, I was so excited. Chatting to strangers gives you such a buzz because there\\'s that element of fear before you talk to someone.\\n\"So I walked from Brockley station back to my house, singing into my phone. And I\\'ve got this really funny voice note, which is like, \\'I\\'m getting high on humans!\\'\"\\nLater, Josephine sent the melody to her musical partner, Anthony West, saying, \"We have to write a song about this tomorrow\".\\n\"I just sent a text back saying, \\'You\\'re crazy,\\'\" he laughs, but the demo was worked up into a full song, High on Humans, which features on the band\\'s upcoming second album, Ultralife.\\nLike her Tube journey, the song tingles with nervous energy, capturing that extraordinary feeling of connecting with other people; a theme that runs through the record.\\nThe duo were moved to write about \"what it means to be a human in this day and age\" after a head-spinning two years, in which their music became an online phenomenon, resulting in a record deal and a tour that ran to more than 200 shows around the world.\\nThe success caught them completely off guard. Oh Wonder was conceived as a songwriting project, whereby the two musicians could subsidise their solo careers by giving songs to other artists.\\nIn September 2014, they created a Soundcloud page and, prompted to describe themselves, wrote: \"Writing duo, one song a month\".\\n\"We thought it was a good way to build up a portfolio over a year,\" explains Josephine. Then their first song, Body Gold, amassed 100,000 plays in just three days.\\n\"We thought it was a fluke,\" says Anthony. \"But then we uploaded something the next month, and the same thing happened. And it just kept snowballing.\\n\"On the first of every month, we\\'d go to a little coffee shop and just release a song and thousands of people would play it. It was amazing. It was the best year ever.\"\\nInitially, they stayed incognito - partly because of their mantra \"it\\'s about the art, not the artist\", but mainly because of Josephine\\'s injuries.\\n\"I had no teeth,\" she grimaces. \"It was a really ill-timed accident.\"\\n\"For a while, she had a little lisp,\" adds Anthony, who had to edit all of his partner\\'s vocals to remove the erroneous \"esses\".\\nRecording on a budget of just Â£200, they hit upon a vocal style where both musicians sing in unison, with Josephine\\'s voice in the centre, and Anthony singing twice, once in the left ear and once in the right.\\nThe technique was actually a happy accident - they\\'d recorded two sets of vocals so the songs could be pitched to both male and female artists, but their managers advised them to blend the two takes, and it became Oh Wonder\\'s unique sonic signature.\\nFans, it seemed, couldn\\'t get enough of it.\\n\"Because we released a song a month over a long period, our fans had a year of their lives soundtracked by our music,\" says Josephine.\\n\"Rather than just, \\'Oh, I really like that song you did,\\' we get, \\'You released that song when I was at university or I had moved to a different country\\'. We get the most heart-warming stories. Hundreds a week.\"\\nAnthony recalls a gig in Grand Rapids, Michigan, where a 50-year-old woman approached the band to express her gratitude for the band\\'s music. Her son, who had recently died of cancer, had been a fan. In his final months, they would wait on tenterhooks for every new release.\\n\"When he died, she was with him and they were listening to his favourite song,\" says Anthony. \"And she said, \\'I thank you so much because now,'}"]},"metadata":{},"execution_count":60}],"source":["checkpoint_model = CorrectionModel(\n","  model_checkpoint=\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/epoch-1_totalsteps-100000\"\n",")\n","checkpoint_predictions = checkpoint_model.batch_inference(test_subset)\n","checkpoint_corrected_indices = eval_get_corrected_indices(checkpoint_predictions)\n","checkpoint_summaries = decode_corrected_summaries(\n","    test_subset,\n","    checkpoint_model,\n","    checkpoint_corrected_indices\n",")\n","checkpoint_summaries[0]"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":94035,"status":"ok","timestamp":1647957293388,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"},"user_tz":240},"id":"ucRDlu0tLj1z","outputId":"bea18b32-6dc6-4d66-b753-5e012c045441"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generating questions...\n","Tokenizing summaries for q-gen...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:46: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n","  'with `validate_args=False` to turn off validation.')\n"]},{"output_type":"stream","name":"stdout","text":["Generating questions (batch 0/179)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beams_buf = indices_buf // vocab_size\n","/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  unfin_idx = idx // beam_size\n"]},{"output_type":"stream","name":"stdout","text":["Generating questions (batch 64/179)...\n","Generating questions (batch 128/179)...\n","Getting answers...\n","Computing metrics...\n","Original sums FEQA scores 0.23779247539548914\n","Corrected sums FEQA scores 0.252162264758953\n","DIFF 0.014369789363463836\n"]}],"source":["import numpy as np\n","orig_feqa_scores, corr_feqa_scores = run_feqa(\n","  checkpoint_summaries, N=len(test_subset)\n",")\n","print(\"Original sums FEQA scores\", np.mean(orig_feqa_scores))\n","print(\"Corrected sums FEQA scores\", np.mean(corr_feqa_scores))\n","\n","print(\"DIFF\", np.mean(corr_feqa_scores) - np.mean(orig_feqa_scores))"]},{"cell_type":"markdown","metadata":{"id":"QcPiZ0x7krwW"},"source":["## Checkpoint 130k steps (epoch 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":180599,"status":"ok","timestamp":1647919390529,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7ptkoeHzG-SgTUcatA-2LM4vPqWpUfFdo2DtG=s64","userId":"01882518168555759889"},"user_tz":240},"id":"sk7KrObRkwJ-","outputId":"1e6b0e07-5bfd-46df-a27e-dcceaaacc5d1"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [02:23<00:00,  6.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Corrected: 976 (97.60%)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 976/976 [00:33<00:00, 29.30it/s]\n"]},{"data":{"text/plain":["{'corrected': 'World number one Wawrinka was beaten in five sets by Stan Wawrinka in the French Open final.',\n"," 'original': 'World number one Novak Djokovic was beaten in five sets by Stan Wawrinka in the French Open final.',\n"," 'source': 'The Swiss eighth seed played magnificently in a 4-6 6-4 6-3 6-4 victory at Roland Garros.\\nWawrinka, 30, brought an end to Djokovic\\'s 28-match winning streak as he claimed his second Grand Slam title.\\nMedia playback is not supported on this device\\nDjokovic had been hoping to become the eighth man to complete the set of all four major titles.\\nBut the Serb will have to wait at least another 12 months before attempting to match the full set of major titles collected by Andre Agassi, Don Budge, Roy Emerson, Roger Federer, Rod Laver, Rafael Nadal and Fred Perry.\\nThe 28-year-old had been a strong favourite to finally get his hands on the Coupe des Mousquetaires after beating nine-time champion Rafael Nadal and third seed Andy Murray, but he was outplayed by Wawrinka.\\n\"It was an incredible atmosphere on court and I felt emotion like I never have before,\" said Wawrinka.\\n\"I would like to thank my coach Magnus Norman. You played in the final without winning but this victory is yours as well as mine.\"\\nDjokovic was effusive in his praise for the new champion: \"There are things that are more important in life than victories and that is character and respect - Stan you are a great champion with big heart.\"\\nTheir last four matches in Grand Slams had gone to five sets and this was every bit as good in terms of quality, with Wawrinka hitting 60 winners as his aggression broke down the seemingly invincible Djokovic defence.\\nThe victory makes him only the second Swiss to win at Roland Garros after Roger Federer, the man he beat in the quarter-finals.\\nHaving lost the first set of the final following a poor service game at 3-3, Wawrinka came storming back with a barrage of winners that left Djokovic looking lost for a response.\\nFour break points came and went in the second set before the fifth arrived in the shape of a set point, and Wawrinka finally converted to level the match.\\nIt was merely a sign of things to come as the eighth seed tore into the Djokovic serve in the third, and despite seeing off three break points for 1-1, there was little the top seed could do four games later.\\nA brilliant forehand winner was followed by an equally breathtaking backhand to earn three break points, and the first was converted as Wawrinka moved forward and hammered a short ball.\\nThe crowd on Court Philippe Chatrier roared as the Swiss hit an outrageous winner around the net post on his way to securing the set.\\nDjokovic was now facing a third French Open final defeat and he dug in, taking advantage of a lull at the opposite end of the court to fashion a 3-0 lead in the fourth.\\nThe match was now on Wawrinka\\'s racquet, however, and he came storming back to level at 3-3 after some brilliant defence earned him the break.\\nDjokovic called on everything he had to stay in touch, finding two volleys - the second a lunging effort reminiscent of his coach Boris Becker - to save break points with the score level in the set.\\nMoments later it looked as though Djokovic would force the fifth set that had seemed inevitable as he moved 0-40 up, but there was another burst of brilliance to come from Wawrinka.\\nA volley, a backhand and a serve got him out of trouble, and he rode the wave of five successive points into the next game as two screaming backhand passes at 4-4 gave him the chance to serve out for the title.\\nIt was never likely to be easy and, after a possible ace was overruled by the umpire on his first match point, the Swiss had to face a break point as Djokovic clung on to his career Slam hopes.\\nThe Serb could only send a forehand wide under pressure, and given a second opportunity to take the championship, Wawrinka steered another of those trademark backhands down the line and raised his arms in triumph.'}"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["checkpoint_model = CorrectionModel(\n","  model_checkpoint=\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/epoch-1_totalsteps-130000\"\n",")\n","checkpoint_predictions = checkpoint_model.batch_inference(test_subset)\n","checkpoint_corrected_indices = eval_get_corrected_indices(checkpoint_predictions)\n","checkpoint_summaries = decode_corrected_summaries(\n","    test_subset,\n","    checkpoint_model,\n","    checkpoint_corrected_indices\n",")\n","checkpoint_summaries[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132381,"status":"ok","timestamp":1647919522897,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7ptkoeHzG-SgTUcatA-2LM4vPqWpUfFdo2DtG=s64","userId":"01882518168555759889"},"user_tz":240},"id":"dbCIiRFQkzyA","outputId":"69c7296e-1afe-4a99-d97a-2b19678b8b38"},"outputs":[{"name":"stdout","output_type":"stream","text":["Generating questions...\n","Tokenizing summaries for q-gen...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:46: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n","  'with `validate_args=False` to turn off validation.')\n"]},{"name":"stdout","output_type":"stream","text":["Generating questions (batch 0/353)...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beams_buf = indices_buf // vocab_size\n","/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  unfin_idx = idx // beam_size\n"]},{"name":"stdout","output_type":"stream","text":["Generating questions (batch 64/353)...\n","Generating questions (batch 128/353)...\n","Generating questions (batch 192/353)...\n","Generating questions (batch 256/353)...\n","Generating questions (batch 320/353)...\n","Getting answers...\n","Computing metrics...\n","Original sums FEQA scores 0.24659687865571164\n","Corrected sums FEQA scores 0.17105397829380842\n","DIFF -0.07554290036190323\n"]}],"source":["import numpy as np\n","orig_feqa_scores, corr_feqa_scores = run_feqa(\n","  checkpoint_summaries, N=100\n",")\n","print(\"Original sums FEQA scores\", np.mean(orig_feqa_scores))\n","print(\"Corrected sums FEQA scores\", np.mean(corr_feqa_scores))\n","\n","print(\"DIFF\", np.mean(corr_feqa_scores) - np.mean(orig_feqa_scores))"]},{"cell_type":"markdown","metadata":{"id":"gUobM7UBsKqY"},"source":["## Checkpoint 140k steps (epoch 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":158995,"status":"ok","timestamp":1647924619372,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7ptkoeHzG-SgTUcatA-2LM4vPqWpUfFdo2DtG=s64","userId":"01882518168555759889"},"user_tz":240},"id":"gliGkv3TsOvk","outputId":"1211ab3f-8797-4670-ef53-707e195bc8c5"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000/1000 [02:23<00:00,  6.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Corrected: 349 (34.90%)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 349/349 [00:11<00:00, 30.30it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'corrected': 'An inquest into the death of a woman who died in a house fire in Aberdare has been told carbon monoxide gas levels were \"16 times the acceptable level\".',\n"," 'original': 'An inquest into the death of a woman who died in a house fire in Denbighshire has been told carbon monoxide gas levels were \"16 times the acceptable level\".',\n"," 'source': 'The body of Kimberley Jones, 25, was found by a paramedic at the house in Cwmbach, Aberdare, on 9 August, 2013.\\nMother-of-one Ms Jones was due to move into the house the following day, but was allowed to stay the night before.\\nTests on the fire showed the flue was ineffective allowing smoke to leak into the room, the Aberdare inquest heard.\\nDuring those tests carbon monoxide gas was at 16 times the acceptable level.\\nMs Jones\\' father, Andrew Jones, told the inquest he knew the owner of the house, Ms Linda Parfitt, as a family friend for 25 years and he arranged to buy the house from her to use as a home for his daughter.\\nMs Parfitt left the property at the start of the week and Mr Jones was decorating it that week.\\nHe said he stayed there for two nights to keep the house secure.\\nHis daughter, who worked as a care worker, was due to stay there on Thursday 8 August, but Mr Jones said he had woken up cold the previous morning so decided to light the fire.\\nHe told the inquest that he told his daughter to keep a window open as he did not want her to die from carbon monoxide poisoning.\\nHe said: \"That will haunt me for the rest of my days.\"\\nMr Jones said his wife called him the following morning as she could not contact their daughter.\\nHe said he went to the house but the emergency services were already there.\\nHe told the coroner he identified his daughter\\'s body later that day.\\nPlumbing inspector Howard Reed told the coroner the fire was dirty with a lot of soot and debris.\\nTests showed its window and door leaked smoke and carbon monoxide tests found that after two hours there were 829 parts per million (ppm) of the gas in the room.\\nA domestic carbon monoxide alarm would sound at about 50 ppm and levels of between 600 and 750ppm are likely to cause fatalities, the hearing was told.\\nDebris on the fire\\'s throat plate, which is used to restrict airflow, was blocking the flue and Mr Reed estimated it had not been removed for \"many years\".\\nThe owner of the house at the time, Ms Parfitt, told the inquest that she and her ex-partner arranged for the fire to be installed.\\nMs Parfitt told the inquest that a vent in the living room had been there prior to moving into the house.\\nShe said that she did not inspect it and could not explain how a magazine cover found its way into the grill opening.\\nWhen shown a picture of smoke coming from the fire during the inspection after Ms Jones died, Miss Parfitt told the coroner: \"I\\'ve never seen smoke coming out of it like that - I\\'m sure about that.\"\\nThe inquest has now been adjourned until later in the year.'}"]},"metadata":{},"execution_count":137}],"source":["checkpoint_model = CorrectionModel(\n","  model_checkpoint=\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/epoch-1_totalsteps-140000\"\n",")\n","checkpoint_predictions = checkpoint_model.batch_inference(test_subset)\n","checkpoint_corrected_indices = eval_get_corrected_indices(checkpoint_predictions)\n","checkpoint_summaries = decode_corrected_summaries(\n","    test_subset,\n","    checkpoint_model,\n","    checkpoint_corrected_indices\n",")\n","checkpoint_summaries[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157677,"status":"ok","timestamp":1647924777035,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7ptkoeHzG-SgTUcatA-2LM4vPqWpUfFdo2DtG=s64","userId":"01882518168555759889"},"user_tz":240},"id":"3ZKtzwEQsPoo","outputId":"a5622b62-544e-4a48-c331-302bb6976f7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generating questions...\n","Tokenizing summaries for q-gen...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:46: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n","  'with `validate_args=False` to turn off validation.')\n"]},{"output_type":"stream","name":"stdout","text":["Generating questions (batch 0/77)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beams_buf = indices_buf // vocab_size\n","/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  unfin_idx = idx // beam_size\n"]},{"output_type":"stream","name":"stdout","text":["Generating questions (batch 64/77)...\n","Getting answers...\n","Computing metrics...\n","Generating questions...\n","Tokenizing summaries for q-gen...\n","Generating questions (batch 0/219)...\n","Generating questions (batch 64/219)...\n","Generating questions (batch 128/219)...\n","Generating questions (batch 192/219)...\n","Getting answers...\n","Computing metrics...\n","Original sums FEQA scores 0.2623776855556351\n","Corrected sums FEQA scores 0.2663767549918951\n","DIFF 0.003999069436259994\n"]}],"source":["import numpy as np\n","orig_feqa_scores, corr_feqa_scores = run_feqa(\n","  checkpoint_summaries, N=100\n",")\n","print(\"Original sums FEQA scores\", np.mean(orig_feqa_scores))\n","print(\"Corrected sums FEQA scores\", np.mean(corr_feqa_scores))\n","\n","print(\"DIFF\", np.mean(corr_feqa_scores) - np.mean(orig_feqa_scores))"]},{"cell_type":"markdown","metadata":{"id":"Kba17Bxhsaad"},"source":["### with `max_examples_per_doc=3`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":88538,"status":"ok","timestamp":1647922846397,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7ptkoeHzG-SgTUcatA-2LM4vPqWpUfFdo2DtG=s64","userId":"01882518168555759889"},"user_tz":240},"id":"1Aqx4RWEsgTW","outputId":"c80ef864-604e-498d-f1e9-b300d451aadf"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [01:16<00:00, 13.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Corrected: 254 (25.40%)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 254/254 [00:08<00:00, 30.85it/s]\n"]},{"data":{"text/plain":["{'corrected': 'An inquest into the death of a woman who died in a house fire in Aberdare has been told carbon monoxide gas levels were \"16 times the acceptable level\".',\n"," 'original': 'An inquest into the death of a woman who died in a house fire in Denbighshire has been told carbon monoxide gas levels were \"16 times the acceptable level\".',\n"," 'source': 'The body of Kimberley Jones, 25, was found by a paramedic at the house in Cwmbach, Aberdare, on 9 August, 2013.\\nMother-of-one Ms Jones was due to move into the house the following day, but was allowed to stay the night before.\\nTests on the fire showed the flue was ineffective allowing smoke to leak into the room, the Aberdare inquest heard.\\nDuring those tests carbon monoxide gas was at 16 times the acceptable level.\\nMs Jones\\' father, Andrew Jones, told the inquest he knew the owner of the house, Ms Linda Parfitt, as a family friend for 25 years and he arranged to buy the house from her to use as a home for his daughter.\\nMs Parfitt left the property at the start of the week and Mr Jones was decorating it that week.\\nHe said he stayed there for two nights to keep the house secure.\\nHis daughter, who worked as a care worker, was due to stay there on Thursday 8 August, but Mr Jones said he had woken up cold the previous morning so decided to light the fire.\\nHe told the inquest that he told his daughter to keep a window open as he did not want her to die from carbon monoxide poisoning.\\nHe said: \"That will haunt me for the rest of my days.\"\\nMr Jones said his wife called him the following morning as she could not contact their daughter.\\nHe said he went to the house but the emergency services were already there.\\nHe told the coroner he identified his daughter\\'s body later that day.\\nPlumbing inspector Howard Reed told the coroner the fire was dirty with a lot of soot and debris.\\nTests showed its window and door leaked smoke and carbon monoxide tests found that after two hours there were 829 parts per million (ppm) of the gas in the room.\\nA domestic carbon monoxide alarm would sound at about 50 ppm and levels of between 600 and 750ppm are likely to cause fatalities, the hearing was told.\\nDebris on the fire\\'s throat plate, which is used to restrict airflow, was blocking the flue and Mr Reed estimated it had not been removed for \"many years\".\\nThe owner of the house at the time, Ms Parfitt, told the inquest that she and her ex-partner arranged for the fire to be installed.\\nMs Parfitt told the inquest that a vent in the living room had been there prior to moving into the house.\\nShe said that she did not inspect it and could not explain how a magazine cover found its way into the grill opening.\\nWhen shown a picture of smoke coming from the fire during the inspection after Ms Jones died, Miss Parfitt told the coroner: \"I\\'ve never seen smoke coming out of it like that - I\\'m sure about that.\"\\nThe inquest has now been adjourned until later in the year.'}"]},"execution_count":120,"metadata":{},"output_type":"execute_result"}],"source":["checkpoint_model = CorrectionModel(\n","  model_checkpoint=\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/epoch-1_totalsteps-140000\"\n",")\n","checkpoint_predictions = checkpoint_model.batch_inference(\n","    test_subset,\n","    max_examples_per_doc=3\n",")\n","checkpoint_corrected_indices = eval_get_corrected_indices(checkpoint_predictions)\n","checkpoint_summaries = decode_corrected_summaries(\n","    test_subset,\n","    checkpoint_model,\n","    checkpoint_corrected_indices\n",")\n","checkpoint_summaries[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"wbR_LivHsheU","outputId":"825b4e7f-cdc9-4267-d88b-ff8dd008b257"},"outputs":[{"name":"stdout","output_type":"stream","text":["Generating questions...\n","Tokenizing summaries for q-gen...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:46: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n","  'with `validate_args=False` to turn off validation.')\n"]},{"name":"stdout","output_type":"stream","text":["Generating questions (batch 0/650)...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beams_buf = indices_buf // vocab_size\n","/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  unfin_idx = idx // beam_size\n"]},{"name":"stdout","output_type":"stream","text":["Generating questions (batch 64/650)...\n","Generating questions (batch 128/650)...\n","Generating questions (batch 192/650)...\n","Generating questions (batch 256/650)...\n","Generating questions (batch 320/650)...\n","Generating questions (batch 384/650)...\n","Generating questions (batch 448/650)...\n","Generating questions (batch 512/650)...\n","Generating questions (batch 576/650)...\n","Generating questions (batch 640/650)...\n","Getting answers...\n","Computing metrics...\n","Generating questions...\n","Tokenizing summaries for q-gen...\n","Generating questions (batch 0/832)...\n","Generating questions (batch 64/832)...\n","Generating questions (batch 128/832)...\n","Generating questions (batch 192/832)...\n","Generating questions (batch 256/832)...\n","Generating questions (batch 320/832)...\n","Generating questions (batch 384/832)...\n","Generating questions (batch 448/832)...\n","Generating questions (batch 512/832)...\n","Generating questions (batch 576/832)...\n","Generating questions (batch 640/832)...\n","Generating questions (batch 704/832)...\n","Generating questions (batch 768/832)...\n","Getting answers...\n","Computing metrics...\n","Original sums FEQA scores 0.253084141864865\n","Corrected sums FEQA scores 0.28209724678956877\n","DIFF 0.02901310492470377\n"]}],"source":["import numpy as np\n","orig_feqa_scores, corr_feqa_scores = run_feqa(\n","  checkpoint_summaries, N=100\n",")\n","print(\"Original sums FEQA scores\", np.mean(orig_feqa_scores))\n","print(\"Corrected sums FEQA scores\", np.mean(corr_feqa_scores))\n","\n","print(\"DIFF\", np.mean(corr_feqa_scores) - np.mean(orig_feqa_scores))"]},{"cell_type":"markdown","source":["## Checkpoint 205k steps (epoch 2)"],"metadata":{"id":"6RF7QIqQy_M_"}},{"cell_type":"code","source":["checkpoint_model = CorrectionModel(\n","  model_checkpoint=\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/epoch-2_totalsteps-205000\"\n",")\n","checkpoint_predictions = checkpoint_model.batch_inference(test_subset)\n","checkpoint_corrected_indices = eval_get_corrected_indices(checkpoint_predictions)\n","checkpoint_summaries = decode_corrected_summaries(\n","    test_subset,\n","    checkpoint_model,\n","    checkpoint_corrected_indices\n",")\n","checkpoint_summaries[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"4mBuSULWzJt5","executionInfo":{"status":"error","timestamp":1647956869352,"user_tz":240,"elapsed":8730,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}},"outputId":"fd3372e8-7ae5-402d-fcee-629c7fba76b6"},"execution_count":56,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-07ca1779b2a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m checkpoint_model = CorrectionModel(\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/epoch-2_totalsteps-205000\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcheckpoint_corrected_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_get_corrected_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/topics-in-nlp-repro-project/model/correction_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_checkpoint)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBartTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"facebook/bart-base\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         self.model = BartForSequenceClassification.from_pretrained(\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         )\n\u001b[1;32m     30\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m                     \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1440\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'data/{key}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UntypedStorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;31m# TODO: Once we decide to break serialization FC, we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0;31m# stop wrapping with _TypedStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import numpy as np\n","orig_feqa_scores, corr_feqa_scores = run_feqa(\n","  checkpoint_summaries, N=len(test_subset)\n",")\n","print(\"Original sums FEQA scores\", np.mean(orig_feqa_scores))\n","print(\"Corrected sums FEQA scores\", np.mean(corr_feqa_scores))\n","\n","print(\"DIFF\", np.mean(corr_feqa_scores) - np.mean(orig_feqa_scores))"],"metadata":{"id":"zjXGN_QBzNcJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##  Done training (280k steps)"],"metadata":{"id":"Qzv42KgTzOmM"}},{"cell_type":"code","source":["checkpoint_model = CorrectionModel(\n","  model_checkpoint=\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/final-epoch-2_totalsteps-283380\"\n",")\n","checkpoint_predictions = checkpoint_model.batch_inference(test_subset)\n","checkpoint_corrected_indices = eval_get_corrected_indices(checkpoint_predictions)\n","checkpoint_summaries = decode_corrected_summaries(\n","    test_subset,\n","    checkpoint_model,\n","    checkpoint_corrected_indices\n",")\n","checkpoint_summaries[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rwdDF7ozTlj","executionInfo":{"status":"ok","timestamp":1647956948492,"user_tz":240,"elapsed":52354,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}},"outputId":"321883a6-0a18-4bc1-c3be-449e97cd572f"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 250/250 [00:39<00:00,  6.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Corrected: 75 (30.00%)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 75/75 [00:02<00:00, 26.10it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'corrected': 'When Josephine broke her nose on the London Underground, it was the beginning of the end for Oh Wonder, the songwriting duo who went on to become a global sensation.',\n"," 'original': 'When Josephine Skousen broke her nose on the London Underground, it was the beginning of the end for Oh Wonder, the songwriting duo who went on to become a global sensation.',\n"," 'source': 'It forced the band to remain anonymous for almost a year: No photographs, no interviews, no videos.\\nBut there was an upside. Last year, as she caught a train home from Heathrow, she sat next to a passenger \"covered in blood [with] no teeth, looking sorry for himself\".\\n\"I tentatively went up to him and his girlfriend and said, \\'I just wanted to let you know you\\'ll be fine\\',\" recalls the 27-year-old.\\n\"\\'Go to the dentist tomorrow, don\\'t panic, you\\'ll be great\\'. And he was like, \\'Oh, thank you so much!\\'.\\n\"And then this guy opposite us piped up, \\'I broke my nose, too!\\'. And suddenly this whole little carriage was talking about their injuries, which was remarkable.\\n\"When I got off the Tube, I was so excited. Chatting to strangers gives you such a buzz because there\\'s that element of fear before you talk to someone.\\n\"So I walked from Brockley station back to my house, singing into my phone. And I\\'ve got this really funny voice note, which is like, \\'I\\'m getting high on humans!\\'\"\\nLater, Josephine sent the melody to her musical partner, Anthony West, saying, \"We have to write a song about this tomorrow\".\\n\"I just sent a text back saying, \\'You\\'re crazy,\\'\" he laughs, but the demo was worked up into a full song, High on Humans, which features on the band\\'s upcoming second album, Ultralife.\\nLike her Tube journey, the song tingles with nervous energy, capturing that extraordinary feeling of connecting with other people; a theme that runs through the record.\\nThe duo were moved to write about \"what it means to be a human in this day and age\" after a head-spinning two years, in which their music became an online phenomenon, resulting in a record deal and a tour that ran to more than 200 shows around the world.\\nThe success caught them completely off guard. Oh Wonder was conceived as a songwriting project, whereby the two musicians could subsidise their solo careers by giving songs to other artists.\\nIn September 2014, they created a Soundcloud page and, prompted to describe themselves, wrote: \"Writing duo, one song a month\".\\n\"We thought it was a good way to build up a portfolio over a year,\" explains Josephine. Then their first song, Body Gold, amassed 100,000 plays in just three days.\\n\"We thought it was a fluke,\" says Anthony. \"But then we uploaded something the next month, and the same thing happened. And it just kept snowballing.\\n\"On the first of every month, we\\'d go to a little coffee shop and just release a song and thousands of people would play it. It was amazing. It was the best year ever.\"\\nInitially, they stayed incognito - partly because of their mantra \"it\\'s about the art, not the artist\", but mainly because of Josephine\\'s injuries.\\n\"I had no teeth,\" she grimaces. \"It was a really ill-timed accident.\"\\n\"For a while, she had a little lisp,\" adds Anthony, who had to edit all of his partner\\'s vocals to remove the erroneous \"esses\".\\nRecording on a budget of just Â£200, they hit upon a vocal style where both musicians sing in unison, with Josephine\\'s voice in the centre, and Anthony singing twice, once in the left ear and once in the right.\\nThe technique was actually a happy accident - they\\'d recorded two sets of vocals so the songs could be pitched to both male and female artists, but their managers advised them to blend the two takes, and it became Oh Wonder\\'s unique sonic signature.\\nFans, it seemed, couldn\\'t get enough of it.\\n\"Because we released a song a month over a long period, our fans had a year of their lives soundtracked by our music,\" says Josephine.\\n\"Rather than just, \\'Oh, I really like that song you did,\\' we get, \\'You released that song when I was at university or I had moved to a different country\\'. We get the most heart-warming stories. Hundreds a week.\"\\nAnthony recalls a gig in Grand Rapids, Michigan, where a 50-year-old woman approached the band to express her gratitude for the band\\'s music. Her son, who had recently died of cancer, had been a fan. In his final months, they would wait on tenterhooks for every new release.\\n\"When he died, she was with him and they were listening to his favourite song,\" says Anthony. \"And she said, \\'I thank you so much because now,'}"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["import numpy as np\n","orig_feqa_scores, corr_feqa_scores = run_feqa(\n","  checkpoint_summaries, N=len(test_subset)\n",")\n","print(\"Original sums FEQA scores\", np.mean(orig_feqa_scores))\n","print(\"Corrected sums FEQA scores\", np.mean(corr_feqa_scores))\n","\n","print(\"DIFF\", np.mean(corr_feqa_scores) - np.mean(orig_feqa_scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQDP0SAszcY6","executionInfo":{"status":"ok","timestamp":1647957151770,"user_tz":240,"elapsed":203282,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}},"outputId":"1cd61701-f4ad-4681-817c-00cc2f76ab6d"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating questions...\n","Tokenizing summaries for q-gen...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:46: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n","  'with `validate_args=False` to turn off validation.')\n"]},{"output_type":"stream","name":"stdout","text":["Generating questions (batch 0/42)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beams_buf = indices_buf // vocab_size\n","/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  unfin_idx = idx // beam_size\n"]},{"output_type":"stream","name":"stdout","text":["Getting answers...\n","Computing metrics...\n","Generating questions...\n","Tokenizing summaries for q-gen...\n","Generating questions (batch 0/358)...\n","Generating questions (batch 64/358)...\n","Generating questions (batch 128/358)...\n","Generating questions (batch 192/358)...\n","Generating questions (batch 256/358)...\n","Generating questions (batch 320/358)...\n","Getting answers...\n","Computing metrics...\n","Original sums FEQA scores 0.2547294884640526\n","Corrected sums FEQA scores 0.2529357562174006\n","DIFF -0.001793732246651969\n"]}]},{"cell_type":"markdown","source":["# Final Eval"],"metadata":{"id":"hhtkxI-cpR5G"}},{"cell_type":"code","source":["final_model = CorrectionModel(\n","  model_checkpoint=\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/final-epoch-2_totalsteps-283380\"\n",")\n","final_predictions = final_model.batch_inference(\n","    test_data\n",")\n","final_corrected_indices = eval_get_corrected_indices(final_predictions)\n","final_summaries = decode_corrected_summaries(\n","    test_data,\n","    final_model,\n","    final_corrected_indices\n",")\n","final_summaries[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iuV3FjQJXc3g","executionInfo":{"status":"ok","timestamp":1647958396495,"user_tz":240,"elapsed":1102532,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}},"outputId":"0402b2f8-f2b1-4872-f662-5324dc994004"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 6792/6792 [17:13<00:00,  6.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Corrected: 1946 (28.65%)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1946/1946 [01:05<00:00, 29.80it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'corrected': \"Gulls manager Kevin Nicholson says he will not receive any money from the sale of Kane O'Kane to Bournemouth.\",\n"," 'original': \"Torquay United manager Kevin Nicholson says he will not receive any money from the sale of Kane O'Kane to Bournemouth.\",\n"," 'source': 'The National League sold the Republic of Ireland midfielder to the Cherries for £175,000 in 2012 and had a 15% sell-on clause included in the deal.\\nO\\'Kane moved for an undisclosed fee, but Nicholson says any money will go to help the cash-strapped club.\\n\"I don\\'t think I\\'ll be getting anything,\" Nicholson told BBC Devon.\\n\"There\\'s more important things.\"\\nThe Gulls are still looking for new owners having been taken over by a consortium of local business people last summer.\\nThey were forced to close down the club\\'s academy and drastically reduce the playing budget after millionaire former owner Thea Bristow left the club.'}"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["import numpy as np\n","orig_feqa_scores, corr_feqa_scores = run_feqa(\n","  final_summaries, N=len(final_summaries)\n",")\n","print(\"Original sums FEQA scores\", np.mean(orig_feqa_scores))\n","print(\"Corrected sums FEQA scores\", np.mean(corr_feqa_scores))\n","\n","print(\"DIFF\", np.mean(corr_feqa_scores) - np.mean(orig_feqa_scores))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xp-dFIpbXg14","executionInfo":{"status":"ok","timestamp":1647971374243,"user_tz":240,"elapsed":4522681,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}},"outputId":"44eac127-4f5e-4809-c6c6-67942635c594"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating questions...\n","Tokenizing summaries for q-gen...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:46: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n","  'with `validate_args=False` to turn off validation.')\n"]},{"output_type":"stream","name":"stdout","text":["Generating questions (batch 0/7581)...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/fairseq/search.py:140: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  beams_buf = indices_buf // vocab_size\n","/usr/local/lib/python3.7/dist-packages/fairseq/sequence_generator.py:651: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  unfin_idx = idx // beam_size\n"]},{"output_type":"stream","name":"stdout","text":["Generating questions (batch 64/7581)...\n","Generating questions (batch 128/7581)...\n","Generating questions (batch 192/7581)...\n","Generating questions (batch 256/7581)...\n","Generating questions (batch 320/7581)...\n","Generating questions (batch 384/7581)...\n","Generating questions (batch 448/7581)...\n","Generating questions (batch 512/7581)...\n","Generating questions (batch 576/7581)...\n","Generating questions (batch 640/7581)...\n","Generating questions (batch 704/7581)...\n","Generating questions (batch 768/7581)...\n","Generating questions (batch 832/7581)...\n","Generating questions (batch 896/7581)...\n","Generating questions (batch 960/7581)...\n","Generating questions (batch 1024/7581)...\n","Generating questions (batch 1088/7581)...\n","Generating questions (batch 1152/7581)...\n","Generating questions (batch 1216/7581)...\n","Generating questions (batch 1280/7581)...\n","Generating questions (batch 1344/7581)...\n","Generating questions (batch 1408/7581)...\n","Generating questions (batch 1472/7581)...\n","Generating questions (batch 1536/7581)...\n","Generating questions (batch 1600/7581)...\n","Generating questions (batch 1664/7581)...\n","Generating questions (batch 1728/7581)...\n","Generating questions (batch 1792/7581)...\n","Generating questions (batch 1856/7581)...\n","Generating questions (batch 1920/7581)...\n","Generating questions (batch 1984/7581)...\n","Generating questions (batch 2048/7581)...\n","Generating questions (batch 2112/7581)...\n","Generating questions (batch 2176/7581)...\n","Generating questions (batch 2240/7581)...\n","Generating questions (batch 2304/7581)...\n","Generating questions (batch 2368/7581)...\n","Generating questions (batch 2432/7581)...\n","Generating questions (batch 2496/7581)...\n","Generating questions (batch 2560/7581)...\n","Generating questions (batch 2624/7581)...\n","Generating questions (batch 2688/7581)...\n","Generating questions (batch 2752/7581)...\n","Generating questions (batch 2816/7581)...\n","Generating questions (batch 2880/7581)...\n","Generating questions (batch 2944/7581)...\n","Generating questions (batch 3008/7581)...\n","Generating questions (batch 3072/7581)...\n","Generating questions (batch 3136/7581)...\n","Generating questions (batch 3200/7581)...\n","Generating questions (batch 3264/7581)...\n","Generating questions (batch 3328/7581)...\n","Generating questions (batch 3392/7581)...\n","Generating questions (batch 3456/7581)...\n","Generating questions (batch 3520/7581)...\n","Generating questions (batch 3584/7581)...\n","Generating questions (batch 3648/7581)...\n","Generating questions (batch 3712/7581)...\n","Generating questions (batch 3776/7581)...\n","Generating questions (batch 3840/7581)...\n","Generating questions (batch 3904/7581)...\n","Generating questions (batch 3968/7581)...\n","Generating questions (batch 4032/7581)...\n","Generating questions (batch 4096/7581)...\n","Generating questions (batch 4160/7581)...\n","Generating questions (batch 4224/7581)...\n","Generating questions (batch 4288/7581)...\n","Generating questions (batch 4352/7581)...\n","Generating questions (batch 4416/7581)...\n","Generating questions (batch 4480/7581)...\n","Generating questions (batch 4544/7581)...\n","Generating questions (batch 4608/7581)...\n","Generating questions (batch 4672/7581)...\n","Generating questions (batch 4736/7581)...\n","Generating questions (batch 4800/7581)...\n","Generating questions (batch 4864/7581)...\n","Generating questions (batch 4928/7581)...\n","Generating questions (batch 4992/7581)...\n","Generating questions (batch 5056/7581)...\n","Generating questions (batch 5120/7581)...\n","Generating questions (batch 5184/7581)...\n","Generating questions (batch 5248/7581)...\n","Generating questions (batch 5312/7581)...\n","Generating questions (batch 5376/7581)...\n","Generating questions (batch 5440/7581)...\n","Generating questions (batch 5504/7581)...\n","Generating questions (batch 5568/7581)...\n","Generating questions (batch 5632/7581)...\n","Generating questions (batch 5696/7581)...\n","Generating questions (batch 5760/7581)...\n","Generating questions (batch 5824/7581)...\n","Generating questions (batch 5888/7581)...\n","Generating questions (batch 5952/7581)...\n","Generating questions (batch 6016/7581)...\n","Generating questions (batch 6080/7581)...\n","Generating questions (batch 6144/7581)...\n","Generating questions (batch 6208/7581)...\n","Generating questions (batch 6272/7581)...\n","Generating questions (batch 6336/7581)...\n","Generating questions (batch 6400/7581)...\n","Generating questions (batch 6464/7581)...\n","Generating questions (batch 6528/7581)...\n","Generating questions (batch 6592/7581)...\n","Generating questions (batch 6656/7581)...\n","Generating questions (batch 6720/7581)...\n","Generating questions (batch 6784/7581)...\n","Generating questions (batch 6848/7581)...\n","Generating questions (batch 6912/7581)...\n","Generating questions (batch 6976/7581)...\n","Generating questions (batch 7040/7581)...\n","Generating questions (batch 7104/7581)...\n","Generating questions (batch 7168/7581)...\n","Generating questions (batch 7232/7581)...\n","Generating questions (batch 7296/7581)...\n","Generating questions (batch 7360/7581)...\n","Generating questions (batch 7424/7581)...\n","Generating questions (batch 7488/7581)...\n","Generating questions (batch 7552/7581)...\n","Getting answers...\n","Computing metrics...\n","Generating questions...\n","Tokenizing summaries for q-gen...\n","Generating questions (batch 0/7523)...\n","Generating questions (batch 64/7523)...\n","Generating questions (batch 128/7523)...\n","Generating questions (batch 192/7523)...\n","Generating questions (batch 256/7523)...\n","Generating questions (batch 320/7523)...\n","Generating questions (batch 384/7523)...\n","Generating questions (batch 448/7523)...\n","Generating questions (batch 512/7523)...\n","Generating questions (batch 576/7523)...\n","Generating questions (batch 640/7523)...\n","Generating questions (batch 704/7523)...\n","Generating questions (batch 768/7523)...\n","Generating questions (batch 832/7523)...\n","Generating questions (batch 896/7523)...\n","Generating questions (batch 960/7523)...\n","Generating questions (batch 1024/7523)...\n","Generating questions (batch 1088/7523)...\n","Generating questions (batch 1152/7523)...\n","Generating questions (batch 1216/7523)...\n","Generating questions (batch 1280/7523)...\n","Generating questions (batch 1344/7523)...\n","Generating questions (batch 1408/7523)...\n","Generating questions (batch 1472/7523)...\n","Generating questions (batch 1536/7523)...\n","Generating questions (batch 1600/7523)...\n","Generating questions (batch 1664/7523)...\n","Generating questions (batch 1728/7523)...\n","Generating questions (batch 1792/7523)...\n","Generating questions (batch 1856/7523)...\n","Generating questions (batch 1920/7523)...\n","Generating questions (batch 1984/7523)...\n","Generating questions (batch 2048/7523)...\n","Generating questions (batch 2112/7523)...\n","Generating questions (batch 2176/7523)...\n","Generating questions (batch 2240/7523)...\n","Generating questions (batch 2304/7523)...\n","Generating questions (batch 2368/7523)...\n","Generating questions (batch 2432/7523)...\n","Generating questions (batch 2496/7523)...\n","Generating questions (batch 2560/7523)...\n","Generating questions (batch 2624/7523)...\n","Generating questions (batch 2688/7523)...\n","Generating questions (batch 2752/7523)...\n","Generating questions (batch 2816/7523)...\n","Generating questions (batch 2880/7523)...\n","Generating questions (batch 2944/7523)...\n","Generating questions (batch 3008/7523)...\n","Generating questions (batch 3072/7523)...\n","Generating questions (batch 3136/7523)...\n","Generating questions (batch 3200/7523)...\n","Generating questions (batch 3264/7523)...\n","Generating questions (batch 3328/7523)...\n","Generating questions (batch 3392/7523)...\n","Generating questions (batch 3456/7523)...\n","Generating questions (batch 3520/7523)...\n","Generating questions (batch 3584/7523)...\n","Generating questions (batch 3648/7523)...\n","Generating questions (batch 3712/7523)...\n","Generating questions (batch 3776/7523)...\n","Generating questions (batch 3840/7523)...\n","Generating questions (batch 3904/7523)...\n","Generating questions (batch 3968/7523)...\n","Generating questions (batch 4032/7523)...\n","Generating questions (batch 4096/7523)...\n","Generating questions (batch 4160/7523)...\n","Generating questions (batch 4224/7523)...\n","Generating questions (batch 4288/7523)...\n","Generating questions (batch 4352/7523)...\n","Generating questions (batch 4416/7523)...\n","Generating questions (batch 4480/7523)...\n","Generating questions (batch 4544/7523)...\n","Generating questions (batch 4608/7523)...\n","Generating questions (batch 4672/7523)...\n","Generating questions (batch 4736/7523)...\n","Generating questions (batch 4800/7523)...\n","Generating questions (batch 4864/7523)...\n","Generating questions (batch 4928/7523)...\n","Generating questions (batch 4992/7523)...\n","Generating questions (batch 5056/7523)...\n","Generating questions (batch 5120/7523)...\n","Generating questions (batch 5184/7523)...\n","Generating questions (batch 5248/7523)...\n","Generating questions (batch 5312/7523)...\n","Generating questions (batch 5376/7523)...\n","Generating questions (batch 5440/7523)...\n","Generating questions (batch 5504/7523)...\n","Generating questions (batch 5568/7523)...\n","Generating questions (batch 5632/7523)...\n","Generating questions (batch 5696/7523)...\n","Generating questions (batch 5760/7523)...\n","Generating questions (batch 5824/7523)...\n","Generating questions (batch 5888/7523)...\n","Generating questions (batch 5952/7523)...\n","Generating questions (batch 6016/7523)...\n","Generating questions (batch 6080/7523)...\n","Generating questions (batch 6144/7523)...\n","Generating questions (batch 6208/7523)...\n","Generating questions (batch 6272/7523)...\n","Generating questions (batch 6336/7523)...\n","Generating questions (batch 6400/7523)...\n","Generating questions (batch 6464/7523)...\n","Generating questions (batch 6528/7523)...\n","Generating questions (batch 6592/7523)...\n","Generating questions (batch 6656/7523)...\n","Generating questions (batch 6720/7523)...\n","Generating questions (batch 6784/7523)...\n","Generating questions (batch 6848/7523)...\n","Generating questions (batch 6912/7523)...\n","Generating questions (batch 6976/7523)...\n","Generating questions (batch 7040/7523)...\n","Generating questions (batch 7104/7523)...\n","Generating questions (batch 7168/7523)...\n","Generating questions (batch 7232/7523)...\n","Generating questions (batch 7296/7523)...\n","Generating questions (batch 7360/7523)...\n","Generating questions (batch 7424/7523)...\n","Generating questions (batch 7488/7523)...\n","Getting answers...\n","Computing metrics...\n","Original sums FEQA scores 0.24391313203716097\n","Corrected sums FEQA scores 0.26279141395998146\n","DIFF 0.018878281922820483\n"]}]},{"cell_type":"code","source":["import json\n","if len(final_summaries) == 1946:\n","  with open(\"/content/drive/MyDrive/CS6741/replication/data/corrected/train_v1_final_280k.jsonl\", \"w\") as f:\n","    for x in final_summaries:\n","      f.write(json.dumps(x) + \"\\n\")\n","  print(\"Persisted summaries\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyed8UpxpTqJ","executionInfo":{"status":"ok","timestamp":1647962664737,"user_tz":240,"elapsed":158,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}},"outputId":"8b5288dc-169e-4021-f986-dbdef9584816"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["Persisted summaries\n"]}]},{"cell_type":"markdown","source":["### Max examples per doc: 3"],"metadata":{"id":"578TNMHfuySN"}},{"cell_type":"code","source":["final_model_limit_samples = CorrectionModel(\n","  model_checkpoint=\"/content/drive/MyDrive/CS6741/replication/model_checkpoints/train_v1/final-epoch-2_totalsteps-283380\"\n",")\n","final_predictions_limit_samples = final_model.batch_inference(\n","    test_data,\n","    max_examples_per_doc=3\n",")\n","final_corrected_indices_limit_samples = eval_get_corrected_indices(final_predictions_limit_samples)\n","final_summaries_limit_samples = decode_corrected_summaries(\n","    test_data,\n","    final_model,\n","    final_corrected_indices_limit_samples\n",")\n","final_summaries_limit_samples[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Iytlor7YKUg","executionInfo":{"status":"ok","timestamp":1647965291078,"user_tz":240,"elapsed":44702,"user":{"displayName":"Anton Abilov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCXNOuOoZdYj-G_8uYmZWHLqoOJVgTAYFyCdjRsw=s64","userId":"15143801842794493438"}},"outputId":"8a36e297-af6d-45e8-f09c-3301e8821801"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Corrected: 1327 (19.54%)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1327/1327 [00:44<00:00, 29.79it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'corrected': \"Britain's Ennis-Hill remains on course to qualify for the Rio Olympics after the second day of the Hypo-Meeting in Gotzis, Germany.\",\n"," 'original': \"Britain's Jessica Ennis-Hill remains on course to qualify for the Rio Olympics after the second day of the Hypo-Meeting in Gotzis, Germany.\",\n"," 'source': \"The Olympic champion, 29, was third overall at the end of a promising first day - traditionally her strongest - with a score of 3,928 points.\\nOn Sunday she leapt a respectable 6.16m in the long jump but threw a disappointing 42.60m in the javelin.\\nWith the 800m remaining, she has 5,544 points, still on course for the 6,200 needed to qualify for the Rio Olympics.\\nEnnis-Hill is competing in her first heptathlon since winning gold at London 2012.\\nA top-12 finish and score of 6,075 points would also secure qualification for this summer's World Championships.\\nCanada's Commonwealth champion and world silver medallist Brianne Theisen-Eaton leads ahead of the final event, remarkably achieving three personal bests on her way to a 5,834 score.\\nFollow latest updates and reports on the second day of the Gotzis Hypo-Meeting on the BBC Sport website on Sunday, 31 May.\"}"]},"metadata":{},"execution_count":83}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["WHXMfpD9dI_l","7DT5Fm4zcE4Q","BfqcSNb1LwG5","UnpE3UXdL1B3","HW0TbyHLVqRL","TRQ0iZkmoIdK","wruLoEhULM2e","QcPiZ0x7krwW","gUobM7UBsKqY","6RF7QIqQy_M_","Qzv42KgTzOmM"],"name":"Inference.ipynb","provenance":[],"background_execution":"on","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"04d44b9a008f41fa80cc6bd28ab8612b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ae9750ff7864e978325b095095c9248":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20d32e3d136f48d99c034c7f6a80d7c7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25248edb44d64bb4b2a62fd3bf18191b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"310011821b5d498c9032b6ad83970882":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f3a292e9cf64885aa5c60f866c43c75":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52335bfac6a641d18d11695c5a4824d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5abef602316d462a9e655c7e4d8719d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5be7398aac6142c5984835498d8213ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dbab2a687a44b0d98cf528ad27d0e10":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5de77521beb6448299b55e4d3cd3fa48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f3a292e9cf64885aa5c60f866c43c75","placeholder":"​","style":"IPY_MODEL_0ae9750ff7864e978325b095095c9248","value":"Downloading: 100%"}},"603a0a3866d7484e852249cf65441ec1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6485d3619d894e58a7f6c02f555b85a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5de77521beb6448299b55e4d3cd3fa48","IPY_MODEL_8e40738381af4d768e2481776ca8bd5f","IPY_MODEL_c1c4fafa51424c9f8ce6735b5cb4f300"],"layout":"IPY_MODEL_7bbcbd4ad7d24dd5929ffb5af1ee2ec0"}},"65d4d18e3d614c28bb10d4e893f1deee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92a7ebd8c7f245b0b736dd74e70fc92e","IPY_MODEL_e88f532c4fd44bd8a7df4b5aee975c46","IPY_MODEL_f567774d13744a848ff9ea9e898ed3e6"],"layout":"IPY_MODEL_957f949b11bb427f8aa0302a38804277"}},"6f1602e7d99d4d358012b1420f93adc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7bbcbd4ad7d24dd5929ffb5af1ee2ec0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e40738381af4d768e2481776ca8bd5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_603a0a3866d7484e852249cf65441ec1","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5abef602316d462a9e655c7e4d8719d9","value":456318}},"8e5c8e2a417341e386c700f02ccbd7f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20d32e3d136f48d99c034c7f6a80d7c7","placeholder":"​","style":"IPY_MODEL_e991f4c466b24e8687fe5a41b69d358b","value":"Downloading: 100%"}},"92a7ebd8c7f245b0b736dd74e70fc92e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25248edb44d64bb4b2a62fd3bf18191b","placeholder":"​","style":"IPY_MODEL_e446227cb57a4ae487604a3f17a122a6","value":"Downloading: 100%"}},"957f949b11bb427f8aa0302a38804277":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ee8b0d16b6b4d70a93621cfee62f13a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f0b9fa631b342f58268e5a8f91bb660":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a13cd5d961e842a19934a854e6dfe68a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4dc0e7ba1bf4febb69cccb158167c6a","placeholder":"​","style":"IPY_MODEL_6f1602e7d99d4d358012b1420f93adc3","value":" 878k/878k [00:00&lt;00:00, 2.87MB/s]"}},"c049e69f60a042a0972ea68003aad62d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1c4fafa51424c9f8ce6735b5cb4f300":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f0b9fa631b342f58268e5a8f91bb660","placeholder":"​","style":"IPY_MODEL_c049e69f60a042a0972ea68003aad62d","value":" 446k/446k [00:00&lt;00:00, 880kB/s]"}},"c26eecf80f1641b786c1d0ec6568cacd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e22c3246123346269f417d09e7650cd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e5c8e2a417341e386c700f02ccbd7f1","IPY_MODEL_e71f97392ee04799810bea4272c645b2","IPY_MODEL_a13cd5d961e842a19934a854e6dfe68a"],"layout":"IPY_MODEL_5be7398aac6142c5984835498d8213ec"}},"e446227cb57a4ae487604a3f17a122a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e71f97392ee04799810bea4272c645b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_310011821b5d498c9032b6ad83970882","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9ee8b0d16b6b4d70a93621cfee62f13a","value":898823}},"e88f532c4fd44bd8a7df4b5aee975c46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c26eecf80f1641b786c1d0ec6568cacd","max":1716,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52335bfac6a641d18d11695c5a4824d2","value":1716}},"e991f4c466b24e8687fe5a41b69d358b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4dc0e7ba1bf4febb69cccb158167c6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f567774d13744a848ff9ea9e898ed3e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dbab2a687a44b0d98cf528ad27d0e10","placeholder":"​","style":"IPY_MODEL_04d44b9a008f41fa80cc6bd28ab8612b","value":" 1.68k/1.68k [00:00&lt;00:00, 71.7kB/s]"}}}}},"nbformat":4,"nbformat_minor":0}