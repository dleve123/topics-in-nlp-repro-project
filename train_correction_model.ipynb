{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10080"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing.prepare_train_dataset import load_paper_summaries, tokenize_data\n",
    "\n",
    "# Load summaries from disk, load validation set since it's faster\n",
    "val = load_paper_summaries(\"data/paper/val.jsonl\")\n",
    "len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.bias', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight', 'classification_head.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Correction Model\n",
    "from model.correction_model import CorrectionModel\n",
    "\n",
    "model = CorrectionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize first 10 examples from val set as the training data for testing\n",
    "train_data = tokenize_data(model.tokenizer, val[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   250,   291,    12,   180,    12,   279, 21624,   313,    56,\n",
       "            10,  5394,  5111,    71,  1690,  6932,   409,    15,    10,  3286,\n",
       "          4731,    31, 15534,     7,   928,     4,     2,     2,   133,   313,\n",
       "         20119,  1003,    11,     5,  5081,  5964, 29040,     9,     5,  3286,\n",
       "            61,  5932,    23, 12424,  4610,  4414,    15,   395,     4,    91,\n",
       "            21,   551,    88,   249,  3469,    11,   928,    53,   423,   703,\n",
       "           396,  1427,     4,   894,    56, 27452,     8, 15671,  7443, 24238,\n",
       "            31,   751,  3971,    25,   614,    25,   111,  4006,   347,     6,\n",
       "         15710,   433,   431,     4,   894,  5601,   142,     5,  3286,  8294,\n",
       "            23,    10,   614, 22917,     7,  1877,  2130,   219,  1650,     4,\n",
       "           133,   313,  4100,   300,   223,    10,  8146,    23, 22958, 29465,\n",
       "          3062,    11, 15534,     8,  7334,    88,     5,   223,  5901, 35859,\n",
       "             9,     5,    78,  3286,    37,   794,   396,  4730,    63,  6381,\n",
       "             4,   133,  3286, 14574,     7,    10,    79, 18439,    31,     5,\n",
       "           315,  4681,  8313,     8,    56,    57,  2934,  5802,    15,     5,\n",
       "           326, 28281,    23, 22958, 29465,  3062,   187,   296,     4,   243,\n",
       "          8294,   396,  3670,     7, 12424,  4610,     6,   147,     5, 21624,\n",
       "            21,  2738,    62,    30,   249,     8,  1128,    13,  1690,  6932,\n",
       "           409,     4,   894,   115,    33,    57,  1340,    50, 10110,    50,\n",
       "           576,    10,  4460,  2861,     6,     5, 10718,   522,   174,     5,\n",
       "          3295,     4,   125,    37,    21, 13335,     8, 14313,    19,   117,\n",
       "           617,   814,   145,   551,     6,  5931,   340,  1218,   431,     4,\n",
       "           133,   313,   115,    67,    33,    57,  4507,     7,     5,   987,\n",
       "          8323,  3131,     4,  1708,    24,    16,  6238,    14,    89,    16,\n",
       "           117,  2447,   696,     8,    14,     5,  1218,    40,    45,  2639,\n",
       "             7, 18021,   123,     6,   309,     7,  5931,     4,  1620, 12940,\n",
       "            16,   233,     9,     5,  1281,     6,     5,   313,    16,   481,\n",
       "             7,  2914,     5,   987,     4,   250,  1565,    13,     5,  5280,\n",
       "         10333,  4305,    36,   347,  5596,    43,    26,     5,  1690,  1722,\n",
       "          4384,    21,    22,  5525,  5394,   113,     7,    28,  4299,    72,\n",
       "          1106,    51,   218,    75,   465,     5,   235,   233,     7,  1690,\n",
       "          1722,   409,     6,    51,    64,    28, 14045,    77,     5,   223,\n",
       "          5901, 35859,   606,    62,    60,    37,    26,     4,   894,   355,\n",
       "            35,    22, 10105,     9,     5, 22917,     8,  3971,   148,     5,\n",
       "          2524,     6,    89,    16,    10,  3814,   810,     7,   106,   149,\n",
       "          4895,     8,  1762,     9, 11747,    72,  1106,    14,   630,    75,\n",
       "          3549,   106,     6,   172,    51,   115,    28, 15003,    77,     5,\n",
       "          3054, 23174,  8845,     6,     8,    14,    64,  1266,    14,    77,\n",
       "             5,   223,  5901, 35859,  5699,   456,     6,    51,    40,  1136,\n",
       "            66,    72, 14693,     7, 15710,   433,   690,     6,     5,   313,\n",
       "            95,   770,     7,   120,    66,     9, 15534,     8,   356,    13,\n",
       "           173,     4, 38962,   493,    16,    10,   919,     9,     5,   796,\n",
       "          1332,     6,    98,  7733,  2071,    64,  1504,     7,     5,   987,\n",
       "            13,  6875,     4,   635,     6,  5656,    15,  7733,  2071,   447,\n",
       "            11,  1444,  1091,    11,   317,     4, 50118,     2],\n",
       "        [    0,   250,   291,    12,   180,    12,   279, 21624,   313,    56,\n",
       "            10,  5394,  5111,    71,  1690,  6932,   409,    15,    10,  3286,\n",
       "          4731,    31, 12940,     7,   928,     4,     2,     2,   133,   313,\n",
       "         20119,  1003,    11,     5,  5081,  5964, 29040,     9,     5,  3286,\n",
       "            61,  5932,    23, 12424,  4610,  4414,    15,   395,     4,    91,\n",
       "            21,   551,    88,   249,  3469,    11,   928,    53,   423,   703,\n",
       "           396,  1427,     4,   894,    56, 27452,     8, 15671,  7443, 24238,\n",
       "            31,   751,  3971,    25,   614,    25,   111,  4006,   347,     6,\n",
       "         15710,   433,   431,     4,   894,  5601,   142,     5,  3286,  8294,\n",
       "            23,    10,   614, 22917,     7,  1877,  2130,   219,  1650,     4,\n",
       "           133,   313,  4100,   300,   223,    10,  8146,    23, 22958, 29465,\n",
       "          3062,    11, 15534,     8,  7334,    88,     5,   223,  5901, 35859,\n",
       "             9,     5,    78,  3286,    37,   794,   396,  4730,    63,  6381,\n",
       "             4,   133,  3286, 14574,     7,    10,    79, 18439,    31,     5,\n",
       "           315,  4681,  8313,     8,    56,    57,  2934,  5802,    15,     5,\n",
       "           326, 28281,    23, 22958, 29465,  3062,   187,   296,     4,   243,\n",
       "          8294,   396,  3670,     7, 12424,  4610,     6,   147,     5, 21624,\n",
       "            21,  2738,    62,    30,   249,     8,  1128,    13,  1690,  6932,\n",
       "           409,     4,   894,   115,    33,    57,  1340,    50, 10110,    50,\n",
       "           576,    10,  4460,  2861,     6,     5, 10718,   522,   174,     5,\n",
       "          3295,     4,   125,    37,    21, 13335,     8, 14313,    19,   117,\n",
       "           617,   814,   145,   551,     6,  5931,   340,  1218,   431,     4,\n",
       "           133,   313,   115,    67,    33,    57,  4507,     7,     5,   987,\n",
       "          8323,  3131,     4,  1708,    24,    16,  6238,    14,    89,    16,\n",
       "           117,  2447,   696,     8,    14,     5,  1218,    40,    45,  2639,\n",
       "             7, 18021,   123,     6,   309,     7,  5931,     4,  1620, 12940,\n",
       "            16,   233,     9,     5,  1281,     6,     5,   313,    16,   481,\n",
       "             7,  2914,     5,   987,     4,   250,  1565,    13,     5,  5280,\n",
       "         10333,  4305,    36,   347,  5596,    43,    26,     5,  1690,  1722,\n",
       "          4384,    21,    22,  5525,  5394,   113,     7,    28,  4299,    72,\n",
       "          1106,    51,   218,    75,   465,     5,   235,   233,     7,  1690,\n",
       "          1722,   409,     6,    51,    64,    28, 14045,    77,     5,   223,\n",
       "          5901, 35859,   606,    62,    60,    37,    26,     4,   894,   355,\n",
       "            35,    22, 10105,     9,     5, 22917,     8,  3971,   148,     5,\n",
       "          2524,     6,    89,    16,    10,  3814,   810,     7,   106,   149,\n",
       "          4895,     8,  1762,     9, 11747,    72,  1106,    14,   630,    75,\n",
       "          3549,   106,     6,   172,    51,   115,    28, 15003,    77,     5,\n",
       "          3054, 23174,  8845,     6,     8,    14,    64,  1266,    14,    77,\n",
       "             5,   223,  5901, 35859,  5699,   456,     6,    51,    40,  1136,\n",
       "            66,    72, 14693,     7, 15710,   433,   690,     6,     5,   313,\n",
       "            95,   770,     7,   120,    66,     9, 15534,     8,   356,    13,\n",
       "           173,     4, 38962,   493,    16,    10,   919,     9,     5,   796,\n",
       "          1332,     6,    98,  7733,  2071,    64,  1504,     7,     5,   987,\n",
       "            13,  6875,     4,   635,     6,  5656,    15,  7733,  2071,   447,\n",
       "            11,  1444,  1091,    11,   317,     4, 50118,     2]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [23:12<00:00, 16.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch time 1392.2345929145813\n",
      "Train epoch loss 0.7118376457975024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [22:14<00:00, 15.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch time 1334.0161528587341\n",
      "Train epoch loss 0.6775305987823577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [21:08<00:00, 15.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Epoch time 1269.0021739006042\n",
      "Train epoch loss 0.6720351892567816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A 20-year-old Romanian man had a lucky escape after stowing away on a plane flying from Vienna to London.'],\n",
       " None,\n",
       " tensor([[ 0.2174, -0.1621]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.correct_summary(\n",
    "    val[0][\"source_text\"], \n",
    "    val[0][\"positive_examples\"][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A 20-year-old Romanian man had a lucky escape after stowing away on a plane flying from Romania to London.'],\n",
       " None,\n",
       " tensor([[ 0.2204, -0.1664]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.correct_summary(\n",
    "    val[0][\"source_text\"], \n",
    "    val[0][\"negative_examples\"][0]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac7ebf3c48d2545a080f53c4a55787a9f29dd0b46ecf55c25cf1850888e74b76"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('topics-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
